{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron - Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook tem como intenção implementar um perceptron para classificar o Iris Dataset. Como um perceptron pode fazer apenas uma classificação linear, a base de dados foi reduzida para que houvesse apenas duas classes. Por padrão, foi removida a classe Iris-virginica, mas pode ser facilmente modificada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para execução do código é necessária a importação dos pacotes random e pprint, como no bloco executável abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Perceptron foi implementado como uma estrutra de dados de mesmo nome e está definida no bloco abaixo. Para instanciá-lo é necessário passar como parâmetro a quantidade de entradas e, opicionalmente, o learning rate e a quantidade de eras.\n",
    "A função de ativação (activation_fn) foi definida como uma função binária, já que existem apenas duas classes.\n",
    "A função de treinamento (fit) recebe como parâmetro uma matriz com as entradas de cada uma instância teste e um vetor de resultados para cada instância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self, input_size, lr=1, epochs=100):\n",
    "        self.weights = [0] * (input_size + 1)\n",
    "        # add one for bias\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "\n",
    "    def activation_fn(self, x):\n",
    "        #print( \" x=\", x)\n",
    "        #funcao binaria\n",
    "        return 1 if x >= 0 else 0\n",
    "\n",
    "        #funcao bipolar\n",
    "        # return 1 if x >= 0 else -1\n",
    "\n",
    "\n",
    "\n",
    "    def weighted_sum(self, x, w):\n",
    "        if(len(x) != len(w)):\n",
    "            raise Exception(\"List with differents sizes\")\n",
    "        r = 0\n",
    "        for i in range(len(w)):\n",
    "            r += x[i] * w[i]\n",
    "        return r\n",
    "\n",
    "    def predict(self, x):\n",
    "        z = self.weighted_sum(self.weights, x)\n",
    "        a = self.activation_fn(z)\n",
    "        return a\n",
    "\n",
    "    def fit(self, X, d):\n",
    "        for _ in range(self.epochs):\n",
    "            for i in range(len(d)):\n",
    "                x = [1] + X[i]\n",
    "                y = self.predict(x)\n",
    "                e = d[i] - y\n",
    "                for j  in range(len(self.weights)):\n",
    "                    self.weights[j] = self.weights[j] + self.lr * e * x[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste do Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo lê o arquivo de dados ignorando a classe armazenada variável \"excluded_class\" que, por padrão, foi definida como a classe \"Iris-virginica\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_class = \"Iris-setosa\"\n",
    "second_class = \"Iris-versicolor\"\n",
    "excluded_class = \"Iris-virginica\"\n",
    "number_of_class_values = 4\n",
    "\n",
    "data_set = []\n",
    "with open(\"iris.txt\", \"r\") as data_set_file:\n",
    "    lines = data_set_file.read().split()\n",
    "    for i in range(len(lines)):\n",
    "        lines[i] = lines[i].split(\",\")\n",
    "    for line in lines:\n",
    "        if(line[-1] != excluded_class):\n",
    "            for j in range(len(line) - 1):\n",
    "                line[j] = float(line[j])\n",
    "            data_set.append(line)\n",
    "\n",
    "if(data_set == []):\n",
    "    print(\"Erro na leitura de arquivo ou arquivo vazio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação do Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O trecho abaixo separa o Dataset em dois conjuntos: um de treinamento e um de teste, cada um deles com metade do tamanho do conjunto de dados inicial. Além disso ele cria um conjunto de resultados para cada novo conjunto, onde cada elemento desses conjuntos recebe o valor 1, se for \"first_class\" (definido por padrão como Iris-setosa) ou 0 se for \"second_class\" (definido por padrão como Iris-versicolor). Nota-se que "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_size = len(data_set)\n",
    "training_set_size = int(data_set_size / 2)\n",
    "testing_set_size = data_set_size - training_set_size\n",
    "\n",
    "data_set_index_to_train = random.sample(range(0, data_set_size), training_set_size)\n",
    "data_set_index_to_test = list(set(range(0, data_set_size)) - set(data_set_index_to_train))\n",
    "\n",
    "\n",
    "training_set = []\n",
    "training_set_answer = []\n",
    "for index in data_set_index_to_test:\n",
    "    training_set.append(data_set[index][:-1])\n",
    "\n",
    "    if(data_set[index][-1] == first_class):\n",
    "        training_set_answer.append(1)\n",
    "    elif(data_set[index][-1] == second_class):\n",
    "        training_set_answer.append(0)\n",
    "\n",
    "testing_set = []\n",
    "testing_set_answer = []\n",
    "mapping_test_index_to_data_index = []\n",
    "for index in data_set_index_to_test:\n",
    "    testing_set.append(data_set[index][:-1])\n",
    "\n",
    "    if(data_set[index][-1] == first_class):\n",
    "        testing_set_answer.append(1)\n",
    "    elif(data_set[index][-1] == second_class):\n",
    "        testing_set_answer.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo instancia o perceptron e executa seu treinamento, imprimindo, em seu fim, o peso de cada entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_0: 0.1\n",
      "W_1: 0.10999999999999993\n",
      "W_2: 0.36\n",
      "W_3: -0.5200000000000001\n",
      "W_4: -0.21999999999999997\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(number_of_class_values, 0.1, 100)\n",
    "\n",
    "perceptron.fit(training_set, training_set_answer)\n",
    "\n",
    "for index, value in enumerate(perceptron.weights):\n",
    "    print(\"W_\" + str(index) + \": \" + str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo executa o teste no perceptron já treinado, calculando e imprimindo o número de acertos e erros, assim como a predição e resultado de cada teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 'Iris-setosa', 'Iris-setosa'],\n",
      " [1, 'Iris-setosa', 'Iris-setosa'],\n",
      " [2, 'Iris-setosa', 'Iris-setosa'],\n",
      " [3, 'Iris-setosa', 'Iris-setosa'],\n",
      " [4, 'Iris-setosa', 'Iris-setosa'],\n",
      " [5, 'Iris-setosa', 'Iris-setosa'],\n",
      " [6, 'Iris-setosa', 'Iris-setosa'],\n",
      " [7, 'Iris-setosa', 'Iris-setosa'],\n",
      " [8, 'Iris-setosa', 'Iris-setosa'],\n",
      " [9, 'Iris-setosa', 'Iris-setosa'],\n",
      " [10, 'Iris-setosa', 'Iris-setosa'],\n",
      " [11, 'Iris-setosa', 'Iris-setosa'],\n",
      " [12, 'Iris-setosa', 'Iris-setosa'],\n",
      " [13, 'Iris-setosa', 'Iris-setosa'],\n",
      " [14, 'Iris-setosa', 'Iris-setosa'],\n",
      " [15, 'Iris-setosa', 'Iris-setosa'],\n",
      " [16, 'Iris-setosa', 'Iris-setosa'],\n",
      " [17, 'Iris-setosa', 'Iris-setosa'],\n",
      " [18, 'Iris-setosa', 'Iris-setosa'],\n",
      " [19, 'Iris-setosa', 'Iris-setosa'],\n",
      " [20, 'Iris-setosa', 'Iris-setosa'],\n",
      " [21, 'Iris-setosa', 'Iris-setosa'],\n",
      " [22, 'Iris-setosa', 'Iris-setosa'],\n",
      " [23, 'Iris-setosa', 'Iris-setosa'],\n",
      " [24, 'Iris-setosa', 'Iris-setosa'],\n",
      " [25, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [26, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [27, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [28, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [29, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [30, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [31, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [32, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [33, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [34, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [35, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [36, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [37, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [38, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [39, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [40, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [41, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [42, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [43, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [44, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [45, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [46, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [47, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [48, 'Iris-versicolor', 'Iris-versicolor'],\n",
      " [49, 'Iris-versicolor', 'Iris-versicolor']]\n",
      "Total de acertos: 50\n",
      "Total de erros: 0\n"
     ]
    }
   ],
   "source": [
    "number_of_right_answers = 0\n",
    "number_of_wrong_answers = 0\n",
    "\n",
    "list_prediction_answer = []\n",
    "\n",
    "for index, test in enumerate(testing_set):\n",
    "    test = [0] + test\n",
    "    prediction = perceptron.predict(test)\n",
    "\n",
    "    if(prediction == testing_set_answer[index]):\n",
    "        number_of_right_answers += 1\n",
    "    else:\n",
    "        number_of_wrong_answers += 1\n",
    "\n",
    "    prediction_answer = [index]\n",
    "    if(prediction == 1):\n",
    "        prediction_answer.append(first_class)\n",
    "    else:\n",
    "        prediction_answer.append(second_class)\n",
    "\n",
    "    if(testing_set_answer[index] == 1):\n",
    "        prediction_answer.append(first_class)\n",
    "    else:\n",
    "        prediction_answer.append(second_class)\n",
    "\n",
    "    list_prediction_answer.append(prediction_answer)\n",
    "\n",
    "pprint.pprint(list_prediction_answer)\n",
    "\n",
    "print(\"Total de acertos: \" + str(number_of_right_answers))\n",
    "print(\"Total de erros: \" + str(number_of_wrong_answers))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
